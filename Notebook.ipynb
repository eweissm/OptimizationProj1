{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "#import math\n",
    "import random\n",
    "import numpy as np\n",
    "#import time\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#from torch.nn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "# environment parameters\n",
    "\n",
    "FRAME_TIME = 0.1  # time interval\n",
    "GRAVITY_ACCEL = 0.12  # gravity constant\n",
    "BOOST_ACCEL = 0.4  # thrust constant\n",
    "\n",
    "PLATFORM_WIDTH = 0.25  # landing platform width\n",
    "PLATFORM_HEIGHT = 0.6  # landing platform height\n",
    "ROTATION_ACCEL = 10 # rotation constant\n",
    "\n",
    "airDensitySeaLevel = .012250\n",
    "terminalVel = 1000  # terminal velocity at sea level\n",
    "C_d = GRAVITY_ACCEL / (airDensitySeaLevel * terminalVel**2)\n",
    "\n",
    "airDensityConstant = -1.186*10**-6\n",
    "\n",
    "W = [11, 2., 11., 3.]\n",
    "\n",
    "numTestStates = 500\n",
    "numOfEpochs = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define system dynamics\n",
    "# Notes:\n",
    "# 0. You only need to modify the \"forward\" function\n",
    "# 1. All variables in \"forward\" need to be PyTorch tensors.\n",
    "# 2. All math operations in \"forward\" has to be differentiable, e.g., default PyTorch functions.\n",
    "# 3. Do not use inplace operations, e.g., x += 1. Please see the following section for an example that does not work.\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dynamics, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(state, action):\n",
    "        \"\"\"\n",
    "        action[0] = thrust controller\n",
    "        action[1] = omega controller\n",
    "        state[0] = x\n",
    "        state[1] = x_dot\n",
    "        state[2] = y\n",
    "        state[3] = y_dot\n",
    "        state[4] = theta\n",
    "        \"\"\"\n",
    "        # Apply gravity\n",
    "        # Note: Here gravity is used to change velocity which is the second element of the state vector\n",
    "        # Normally, we would do x[1] = x[1] + gravity * delta_time\n",
    "        # but this is not allowed in PyTorch since it overwrites one variable (x[1]) that is part of the computational graph to be differentiated.\n",
    "        # Therefore, I define a tensor dx = [0., gravity * delta_time], and do x = x + dx. This is allowed...\n",
    "        delta_state_gravity = t.tensor([0., 0., 0., -GRAVITY_ACCEL * FRAME_TIME, 0.])\n",
    "        # Thrust\n",
    "        # Note: Same reason as above. Need a 5-by-1 tensor.\n",
    "        N = len(state)\n",
    "        state_tensor = t.zeros((N, 5))\n",
    "\n",
    "        state_tensor[:, 1] = -t.sin(state[:, 4])\n",
    "\n",
    "        state_tensor[:, 3] = t.cos(state[:, 4])\n",
    "\n",
    "        delta_state_acc = BOOST_ACCEL * FRAME_TIME * t.mul(state_tensor, action[:, 0].reshape(-1, 1))\n",
    "\n",
    "        # Theta\n",
    "        state_tensor_drag = t.zeros((N, 5))\n",
    "        state_tensor_drag[:, 1] = - C_d * airDensitySeaLevel * t.mul(t.exp(t.mul(state[:, 2], airDensityConstant)), t.mul(state[:, 1], state[:, 1]))\n",
    "\n",
    "        state_tensor_drag[:, 3] = C_d * airDensitySeaLevel * t.mul(t.exp(t.mul(state[:, 2], airDensityConstant)), t.mul(state[:, 3], state[:, 3]))\n",
    "        delta_state_drag = FRAME_TIME * state_tensor_drag\n",
    "\n",
    "        delta_state_theta = FRAME_TIME*ROTATION_ACCEL * t.mul(t.tensor([0., 0., 0., 0, -1.]), action[:, 1].reshape(-1, 1))\n",
    "\n",
    "\n",
    "        state = state + delta_state_acc + delta_state_gravity + delta_state_theta + delta_state_drag\n",
    "        # Update state\n",
    "        step_mat = t.tensor([[1., FRAME_TIME, 0., 0., 0.],\n",
    "                                 [0., 1., 0., 0., 0.],\n",
    "                                 [0., 0., 1., FRAME_TIME, 0.],\n",
    "                                 [0., 0., 0., 1., 0.],\n",
    "                                 [0., 0., 0., 0., 1.]])\n",
    "\n",
    "        state = t.matmul(step_mat, t.transpose(state, 0, 1))\n",
    "\n",
    "        return t.transpose(state, 0, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# a deterministic controller\n",
    "# Note:\n",
    "# 0. You only need to change the network architecture in \"__init__\"\n",
    "# 1. nn.Sigmoid outputs values from 0 to 1, nn.Tanh from -1 to 1\n",
    "# 2. You have all the freedom to make the network wider (by increasing \"dim_hidden\") or deeper (by adding more lines to nn.Sequential)\n",
    "# 3. Always start with something simple\n",
    "\n",
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_input, dim_hidden, dim_h2, dim_output):\n",
    "        \"\"\"\n",
    "        dim_input: # of system states\n",
    "        dim_output: # of actions\n",
    "        dim_hidden: up to you\n",
    "        \"\"\"\n",
    "\n",
    "        super(Controller, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(dim_input, dim_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim_hidden, dim_h2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim_h2, dim_output),\n",
    "            # You can add more layers here\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        action = self.network(state)\n",
    "        return action\n",
    "\n",
    "\n",
    "# the simulator that rolls out x(1), x(2), ..., x(T)\n",
    "# Note:\n",
    "# 0. Need to change \"initialize_state\" to optimize the controller over a distribution of initial states\n",
    "# 1. self.action_trajectory and self.state_trajectory stores the action and state trajectories along time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Simulation(nn.Module):\n",
    "\n",
    "    def __init__(self, controller, dynamics, T):\n",
    "        super(Simulation, self).__init__()\n",
    "        self.state = self.initialize_state()\n",
    "        self.controller = controller\n",
    "        self.dynamics = dynamics\n",
    "        self.T = T\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "        for _ in range(T):\n",
    "            action = self.controller.forward(state)\n",
    "            state = self.dynamics.forward(state, action)\n",
    "            self.action_trajectory.append(action)\n",
    "            self.state_trajectory.append(state)\n",
    "        return self.error(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state():\n",
    "        states = t.ones(numTestStates, 5)\n",
    "\n",
    "        for i in range(0, numTestStates):\n",
    "            states[i][0] = random.uniform(0, 1)\n",
    "            states[i][1] = random.uniform(0, 1)\n",
    "            states[i][2] = random.uniform(0, 1)\n",
    "            states[i][3] = random.uniform(0, 1)\n",
    "            states[i][4] = random.uniform(0, 1)\n",
    "        print(states)\n",
    "        return t.tensor(states, requires_grad=False).float()\n",
    "\n",
    "    def error(self, state):\n",
    "        errorCumulative = sum(W[0] * state[:, 0] ** 2 + W[1] * state[:, 1] ** 2 + W[2] * (state[:, 2] - PLATFORM_HEIGHT) ** 2 + W[3] * state[:, 3] ** 2)\n",
    "        #print(errorCumulative)\n",
    "\n",
    "        return errorCumulative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "# Note:\n",
    "# 0. LBFGS is a good choice if you don't have a large batch size (i.e., a lot of initial states to consider simultaneously)\n",
    "# 1. You can also try SGD and other momentum-based methods implemented in PyTorch\n",
    "# 2. You will need to customize \"visualize\"\n",
    "# 3. loss.backward is where the gradient is calculated (d_loss/d_variables)\n",
    "# 4. self.optimizer.step(closure) is where gradient descent is done\n",
    "\n",
    "class Optimize:\n",
    "    def __init__(self, simulation):\n",
    "        self.simulation = simulation\n",
    "        self.parameters = simulation.controller.parameters()\n",
    "        self.optimizer = optim.LBFGS(self.parameters, lr=0.01)\n",
    "#try adam\n",
    "    def step(self):\n",
    "        def closure():\n",
    "            loss = self.simulation(self.simulation.state)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        return closure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    " def train(self, epochs,T):\n",
    "\n",
    "        lossArray= np.zeros(numOfEpochs)\n",
    "        combAvgSS = np.empty((0, 4), float)\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.step()\n",
    "            lossArray[epoch]= loss\n",
    "            print('[%d] Avg Loss per state: %.3f' % (epoch + 1, loss/numTestStates))\n",
    "            StateSpace=np.array([self.simulation.state_trajectory[T-1].detach().numpy() ])\n",
    "\n",
    "            avgSS =np.zeros([1,4])\n",
    "            avgSS[0, 0] = np.mean(StateSpace[:,:, 0])\n",
    "            avgSS[0, 1] = np.mean(StateSpace[:,:, 1])\n",
    "            avgSS[0, 2] = np.mean(StateSpace[:,:, 2])\n",
    "            avgSS[0, 3] = np.mean(StateSpace[:,:, 3])\n",
    "\n",
    "            print(avgSS)\n",
    "\n",
    "\n",
    "            combAvgSS = np.append(combAvgSS, avgSS, axis = 0)\n",
    "            plt.figure(1)\n",
    "            self.visualize(T, epoch)\n",
    "        epochNum = np.linspace(1, epochs, epochs)\n",
    "        plt.figure(2)\n",
    "        plt.plot(epochNum, lossArray)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        stateNames = [\"X\", \"V_X\", \"Y\", \"V_Y\"]\n",
    "        fig, ax = plt.subplots(figsize=(18, 10))\n",
    "        im = ax.imshow(combAvgSS.T)\n",
    "\n",
    "        cbar = ax.figure.colorbar(im, ax=ax, cmap=\"YlGn\", orientation = \"horizontal\")\n",
    "\n",
    "\n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_xticks(np.arange(len(epochNum)), labels=epochNum)\n",
    "        ax.set_yticks(np.arange(len(stateNames)), labels=stateNames)\n",
    "\n",
    "        #Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",rotation_mode=\"anchor\")\n",
    "\n",
    "        # for i in range(len(stateNames)):\n",
    "        #     for j in range(len(epochNum)):\n",
    "        #         text = ax.text(j,i, combAvgSS.T[i, j], ha=\"center\", va=\"center\", color=\"w\", fontsize=\"x-small\")\n",
    "\n",
    "        ax.set_title(\"State Space Per Generation\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    " def visualize(self,T, Epoch):\n",
    "        data = np.array([self.simulation.state_trajectory[i].detach().numpy() for i in range(self.simulation.T)])\n",
    "\n",
    "        x = data[T-1,:, 0]\n",
    "        vx = data[:, 1]\n",
    "        y = data[T-1,:, 2]\n",
    "        vy = data[:, 3]\n",
    "\n",
    "        plt.plot(x, y, 'k.')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(Epoch+1)\n",
    "        plt.plot((0), 'r.')\n",
    "        plt.xlim([-5, 5])\n",
    "        plt.ylim([-5, 5])\n",
    "        plt.show()\n",
    "        plt.clf()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7622, 0.3001, 0.7373, 0.3908, 0.5882],\n",
      "        [0.9453, 0.8517, 0.9659, 0.3954, 0.3668],\n",
      "        [0.4476, 0.3075, 0.5694, 0.1845, 0.6581],\n",
      "        ...,\n",
      "        [0.6571, 0.4778, 0.5148, 0.7623, 0.4580],\n",
      "        [0.7367, 0.7812, 0.5797, 0.7198, 0.3597],\n",
      "        [0.4526, 0.4892, 0.3929, 0.6884, 0.2154]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ericw\\AppData\\Local\\Temp\\ipykernel_10296\\4253327723.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return t.tensor(states, requires_grad=False).float()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Optimize' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m s \u001B[38;5;241m=\u001B[39m Simulation(c, d, T)  \u001B[38;5;66;03m# define simulation\u001B[39;00m\n\u001B[0;32m     10\u001B[0m o \u001B[38;5;241m=\u001B[39m Optimize(s)  \u001B[38;5;66;03m# define optimizer\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[43mo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m(numOfEpochs,T)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Optimize' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "# Now it's time to run the code!\n",
    "T = 50  # number of time steps\n",
    "dim_input = 5  # state space dimensions\n",
    "dim_hidden = 8  # latent dimensions\n",
    "dim_h2 = 5\n",
    "dim_output = 2  # action space dimensions\n",
    "d = Dynamics()  # define dynamics\n",
    "c = Controller(dim_input, dim_hidden,dim_h2, dim_output)  # define controller\n",
    "s = Simulation(c, d, T)  # define simulation\n",
    "o = Optimize(s)  # define optimizer\n",
    "o.train(numOfEpochs,T)  # solve the optimization problem"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
